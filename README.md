# ğŸˆ YOLO Model Comparison Tool

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python Version">
  <img src="https://img.shields.io/badge/Flask-2.0+-green.svg" alt="Flask Version">
  <img src="https://img.shields.io/badge/YOLOv8-Ultralytics-orange.svg" alt="YOLO Version">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License">
</div>

<br>

A **powerful Flask web application** that provides an intuitive interface to upload images and compare the performance of two different YOLOv8 models for object detection. Specifically tailored for analyzing **'football'** and **'cone'** detections, but easily adaptable for other object classes.

---

## âœ¨ Features

### ğŸ–¥ï¸ **Web-Based Interface**
- Clean, modern UI for uploading multiple images
- Drag-and-drop functionality for seamless file uploads
- Real-time progress tracking during analysis

### ğŸ”„ **Side-by-Side Comparison**
- Visual comparison of both models on each image
- **Color-coded bounding boxes**: 
  - ğŸŸ¢ **Green** for Model 1 detections
  - ğŸ”µ **Blue** for Model 2 detections

### ğŸ“Š **Detailed Analytics**
- **Per-image statistics**: Detection counts and confidence scores
- **Class-specific analysis**: Individual metrics for each object type
- **Speed benchmarks**: Preprocessing, inference, and postprocessing times

### ğŸ† **Performance Winner**
- Intelligent algorithm determines the better-performing model
- **Scoring system** based on detection accuracy and confidence
- Per-image and overall performance rankings

### ğŸ“ˆ **Comprehensive Summary**
- **Aggregate statistics** across all uploaded images
- Total detections and average confidence scores
- Model comparison with detailed breakdowns

---

## ğŸ“ Project Structure

```
ğŸ“¦ YOLO-Model-Comparison-Tool/
â”œâ”€â”€ ğŸ app.py                  # Main Flask application
â”œâ”€â”€ ğŸ“‹ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“– README.md               # Documentation
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“ models/                 # ğŸ”´ IMPORTANT: Place your models here
â”‚   â”œâ”€â”€ ğŸ¯ best_model_1.pt     # Your first YOLO model
â”‚   â””â”€â”€ ğŸ¯ best_model_2.pt     # Your second YOLO model
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“ templates/              # HTML templates
â”‚   â””â”€â”€ ğŸŒ index.html          # Main web interface
â”œâ”€â”€ 
â””â”€â”€ ğŸ“ static/                 # Auto-generated folders
    â”œâ”€â”€ ğŸ“ uploads/            # Original uploaded images
    â””â”€â”€ ğŸ“ processed/          # Images with bounding boxes
```

---

## ğŸš€ Setup and Installation

### 1ï¸âƒ£ **Get the Code**
```bash
git clone <repository-url>
cd MODEL_TEST_APP
```

### 2ï¸âƒ£ **Create Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ **Install Dependencies**
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ **Prepare Your Models**
- Create a `models/` folder in the root directory
- Place your trained YOLOv8 model files (`.pt`) inside
- **âš ï¸ IMPORTANT**: Rename them to:
  - `best_model_1.pt`
  - `best_model_2.pt`

### 5ï¸âƒ£ **Launch the Application**
```bash
# Development mode
python app.py

# Or using Flask command
flask run
```

### 6ï¸âƒ£ **Access the Interface**
Open your browser and navigate to: **http://127.0.0.1:5000**

---

## ğŸ¯ How to Use

| Step | Action | Description |
|------|--------|-------------|
| 1ï¸âƒ£ | **Upload** | Navigate to the web interface and upload your test images |
| 2ï¸âƒ£ | **Select** | Choose multiple images (PNG, JPG, JPEG) via drag-drop or click |
| 3ï¸âƒ£ | **Analyze** | Click "Analyze Performance" to start the comparison |
| 4ï¸âƒ£ | **Wait** | Processing time depends on image count and model complexity |
| 5ï¸âƒ£ | **Review** | Examine detailed results and overall performance summary |

---

## ğŸ† Comparison Methodology

Our intelligent scoring system evaluates models based on:

### ğŸ“Š **Scoring Criteria**

| Metric | Points | Description |
|--------|--------|-------------|
| ğŸ¯ **Total Detections** | +1.0 | Model with more overall detections |
| ğŸ–ï¸ **Average Confidence** | +1.0 | Model with higher confidence scores |
| âš¡ **Inference Speed** | +1.0 | Model with faster processing time |
| ğŸˆ **Football Detections** | +0.5 | Model detecting more footballs |
| ğŸš§ **Cone Detections** | +0.5 | Model detecting more cones |

### ğŸ… **Winner Determination**
- Model with **highest total score** wins each image
- **Tie-breaker**: Similar performance noted
- **Overall champion**: Model winning most images

> ğŸ’¡ **Note**: This is a heuristic evaluation tool and doesn't replace rigorous testing with labeled ground truth datasets.

---

## ğŸ“Š Performance Metrics

The application tracks and displays:

- â±ï¸ **Processing Speed**: Preprocess, inference, and postprocess times
- ğŸ¯ **Detection Accuracy**: Count and confidence for each class
- ğŸ“ˆ **Comparative Analysis**: Side-by-side model performance
- ğŸ† **Winner Statistics**: Per-image and overall rankings

---

## ğŸ”§ Technical Requirements

- **Python**: 3.8 or higher
- **Flask**: 2.0+
- **OpenCV**: For image processing
- **Ultralytics**: For YOLO model support
- **NumPy**: For numerical operations

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

<div align="center">
  <p>Made with â¤ï¸ for computer vision enthusiasts</p>
  <p>â­ Star this repo if you find it useful!</p>
</div>